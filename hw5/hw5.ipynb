{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M280 Homework5\n",
    "* Author: Shuang Gao\n",
    "* Date: 2018/06/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider again the MLE of the Dirichlet-multinomial model. In [HW4](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw4/hw04.html), we worked out a Newton's method. In this homework, we explore the MM and EM approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Show that, given iid observations $\\mathbf{x}_1,\\ldots,\\mathbf{x}_n$, the log-likelihood can be written as\n",
    "$$\n",
    "L(\\alpha) = \\sum_{i=1}^n \\ln \\binom{|\\mathbf{x}_i|}{\\mathbf{x}_i}\n",
    "+\\sum_{i=1}^n \\sum_{j=1}^d \\sum_{k=0}^{x_{ij}-1} \\ln(\\alpha_j+k) - \\sum_{i=1}^n \\sum_{k=0}^{|\\mathbf{x}_i|-1} \\ln(|\\alpha|+k).\n",
    "$$\n",
    "Hint: $\\Gamma(a + k) / \\Gamma(a) = a (a + 1) \\cdots (a+k-1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Solution**\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& \\because \\mathbf{x_1},...,\\mathbf{x_n} \\text{ are independent}\\\\ \n",
    "& \\therefore f(\\mathbf{x_1},...,\\mathbf{x_n} \\mid \\alpha) \n",
    "= f(\\mathbf{x_1}\\mid \\alpha)...f(\\mathbf{x_n\\mid \\alpha})\n",
    "\\end{align}\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "\\therefore f(\\mathbf{x_1},...,\\mathbf{x_n} \\mid \\alpha) \n",
    "= \\prod_{i=1}^n \\binom{|\\mathbf{x_i}|}{\\mathbf{x_i}} \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j+x_{ij})}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\alpha|+|\\mathbf{x_i}|)}\n",
    "\\end{align}\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "\\therefore L(\\alpha) \n",
    "&= \\ln (\\prod_{i=1}^n \\binom{|\\mathbf{x_i}|}{\\mathbf{x_i}} \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j+x_{ij})}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\alpha|+|\\mathbf{x_i}|)})\\\\\n",
    "&= \\sum_{i=1}^n \\ln \\binom{|\\mathbf{x}_i|}{\\mathbf{x}_i} + \\sum_{i=1}^n \\sum_{j=1}^d [\\ln \\Gamma(\\alpha_j + x_{ij}) - \\ln \\Gamma(\\alpha_j)] - \\sum_{i=1}^n [\\ln \\Gamma(|\\alpha|+|\\mathbf{x}_i|) - \\ln \\Gamma(|\\alpha|)]\\\\\n",
    "&= \\sum_{i=1}^n \\ln \\binom{|\\mathbf{x}_i|}{\\mathbf{x}_i} + \\sum_{i=1}^n \\sum_{j=1}^d \\ln \\frac{\\Gamma(\\alpha_j+x_{ij})}{\\Gamma(\\alpha_j)} -\\sum_{i=1}^n \\ln \\frac{\\Gamma(|\\alpha|+|x_i|)}{\\Gamma(|\\alpha|)}\\\\\n",
    "&= \\sum_{i=1}^n \\ln \\binom{|\\mathbf{x}_i|}{\\mathbf{x}_i} + \\sum_{i=1}^n \\sum_{j=1}^d\\ln [\\prod_{k=0}^{x_{ij}-1}(\\alpha_j+k)]-\\sum_{i=1}^n\\ln[\\prod_{k=0}^{|\\mathbf{x_i}|-1}(|\\alpha|+k)] \\\\\n",
    "&=  \\sum_{i=1}^n \\ln \\binom{|\\mathbf{x}_i|}{\\mathbf{x}_i} + \\sum_{i=1}^n \\sum_{j=1}^d \\sum_{k=0}^{x_{ij}-1} \\ln(\\alpha_j+k)-\\sum_{i=1}^n\\sum_{k=0}^{|\\mathbf{x_i}|-1}\\ln(|\\alpha|+k)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Suppose $(P_1,\\ldots,P_d) \\in \\Delta_d = \\{\\mathbf{p}: p_i \\ge 0, \\sum_i p_i = 1\\}$ follows a Dirichlet distribution with parameter $\\alpha = (\\alpha_1,\\ldots,\\alpha_d)$. Show that\n",
    "$$\n",
    "\t\\mathbf{E}(\\ln P_j) = \\Psi(\\alpha_j) - \\Psi(|\\alpha|),\n",
    "$$\n",
    "where $\\Psi(z) = \\Gamma'(z)/\\Gamma(z)$ is the digamma function and $|\\alpha| = \\sum_{j=1}^d \\alpha_j$. Hint: Differentiate the identity \n",
    "$$\n",
    "1 = \\int_{\\Delta_d} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1} \\, d\\mathbf{p}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Solution**\n",
    "Differentiate the identity with respect to $\\alpha_j$,\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{d\\alpha_j}1 &= \\frac{d}{d\\alpha_j}\\int_{\\mathbf{p}_1}^{{\\mathbf{p}_2}} \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1} \\, d\\mathbf{p}\\\\\n",
    "0 &= \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d \\mathbf{p_2}_j^{\\alpha_j-1} \\frac{d}{d\\alpha_j}\\mathbf{p}_2\n",
    "-\\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d \\mathbf{p_1}_j^{\\alpha_j-1} \\frac{d}{d\\alpha_j}\\mathbf{p}_1+\\int_{\\mathbf{p}_1}^{{\\mathbf{p}_2}}\\frac{d}{d\\alpha_j}[ \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1}] \\, d\\mathbf{p}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "$$\n",
    "\\because \\frac{d}{d\\alpha_j}\\mathbf{p}_2=0 \\,\\frac{d}{d\\alpha_j}\\mathbf{p}_1=0\\\\\n",
    "\\therefore \\int_{\\mathbf{p}_1}^{{\\mathbf{p}_2}}\\frac{d}{d\\alpha_j}[ \\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1}] \\, d\\mathbf{p}=0 \n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    " \\int_{\\mathbf{p}_1}^{{\\mathbf{p}_2}}[\\prod_{i=1}^d p_i^{\\alpha_i - 1}\\frac{\\Gamma(|\\alpha|)'}{\\prod_{i=1}^{d}\\Gamma(\\alpha_i)}-\\frac{\\Gamma(|\\alpha|)}{\\prod_{i\\neq j}^d\\Gamma(\\alpha_i)}\\frac{\\Gamma(\\alpha_j)'}{\\Gamma(\\alpha_j)}^2\\prod_{i=1}^dp_i^{\\alpha_i-1}+\\frac{\\Gamma(|\\alpha|)}{\\prod_{i= 1}^d\\Gamma(\\alpha_i)}\\prod_{i\\neq j}^d p_i^{\\alpha_i-1}\\ln(p_j) p_j^{\\alpha_j-1}]\\, d\\mathbf{p}\\, d\\mathbf{p}=0\\\\\n",
    "\\int_{\\mathbf{p}_1}^{{\\mathbf{p}_2}}\\prod_{i=1}^d p_i^{\\alpha_i - 1}\\frac{\\Gamma(|\\alpha|)'}{\\prod_{i=1}^{d}\\Gamma(\\alpha_i)}\\frac{\\Gamma(|\\alpha|)}{\\Gamma(|\\alpha|)}\\, d\\mathbf{p}-\\int_{\\mathbf{p}_1}^{{\\mathbf{p}_2}}\\frac{\\Gamma(|\\alpha|)}{\\prod_{i=1}^d\\Gamma(\\alpha_i)}\\frac{\\Gamma(\\alpha_j)'}{\\Gamma(\\alpha_j)}\\prod_{i=1}^dp_i^{\\alpha_i-1}\\, d\\mathbf{p}+\\int_{\\mathbf{p}_1}^{{\\mathbf{p}_2}}\\frac{\\Gamma(|\\alpha|)}{\\prod_{i= 1}^d\\Gamma(\\alpha_i)}\\prod_{i=1}^d p_i^{\\alpha_i-1}\\ln(p_j)\\, d\\mathbf{p}=0\\\\\n",
    "\\frac{\\Gamma(|\\alpha|)'}{\\Gamma(|\\alpha|)}-\\frac{\\Gamma(\\alpha_j)'}{\\Gamma(\\alpha_j)}+\\mathbf{E}(\\ln p_j)=0\\\\\n",
    "\\therefore \\mathbf{E}(\\ln p_j)=\\Psi(\\alpha_j) - \\Psi(|\\alpha|)\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "The admixture representation of the Dirichlet-multinomial distribution suggests that we can treat the unobserved multinomial parameters $\\mathbf{p}_1,\\ldots,\\mathbf{p}_n$ as missing data and derive an EM algorithm. Show that the Q function is\n",
    "$$\n",
    "    Q(\\alpha|\\alpha^{(t)}) = \n",
    "\\sum_{j=1}^d \\sum_{i=1}^n \\alpha_j \\left[\\Psi(x_{ij}+\\alpha_j^{(t)}) - \\Psi(|\\mathbf{x}_i|+|\\alpha^{(t)}|)\\right] - n \\sum_{j=1}^d \\ln \\Gamma(\\alpha_j) + n \\ln \\Gamma(|\\alpha|) + c^{(t)},\n",
    "$$\n",
    "where $c^{(t)}$ is a constant irrelevant to optimization. Comment on why it is not easy to maximize the Q function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Solution**\n",
    "\n",
    "$\\mathbf{p_1},..., \\mathbf{p_n}$ are independent Dirichlet distribution, therefore "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
