{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M280 Homework 2\n",
    "* Author: Shuang Gao\n",
    "* Date: 2018/05/02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Implement the algorithm with arguments:  $X$  (data, each row is a vectorized image), rank  $r$ , convergence tolerance, and optional starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnmf (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nnmf(\n",
    " X::Matrix{T}, \n",
    " r::Int;\n",
    " maxiter::Int = 1000, \n",
    " tol::T = 1e-4,\n",
    " V::Matrix{T} = rand(T, size(X, 1), r),\n",
    " W::Matrix{T} = rand(T, r, size(X, 2))\n",
    " )  where T <: AbstractFloat\n",
    "\n",
    "    # store V*W\n",
    "    mul_VW = zeros(size(X))\n",
    "    \n",
    "    # initialize the denomenator and numerator for V update\n",
    "    denomenator_V = zeros(size(V))\n",
    "    numerator_V = zeros(size(V))\n",
    "    \n",
    "    # initialize the denomenator and numerator for W update\n",
    "    denomenator_W = zeros(size(W))\n",
    "    numerator_W = zeros(size(W))\n",
    "    \n",
    "    # initialize the matrix to store r by r matrix\n",
    "    out_rr = zeros(r, r)\n",
    "    \n",
    "    # store the initial norm L\n",
    "    # norm() is default to be Frobenius norm\n",
    "    L = sum(abs2, X - A_mul_B!(mul_VW, V, W))\n",
    "    #L = vecnorm(X - A_mul_B!(mul_VW, V, W))^2\n",
    "    \n",
    "    for t in 1:maxiter # stop after 1000 iterations        \n",
    "        # update v \n",
    "        # denomenator_V = V * W * W'\n",
    "        # numerator_V = X * W' \n",
    "        V .= V .* (A_mul_Bt!(numerator_V, X, W) ./ A_mul_B!(denomenator_V, V, A_mul_Bt!(out_rr, W, W)))\n",
    "        \n",
    "        # update denomenator \n",
    "        # denomenator_W = V' * V * W\n",
    "        # numerator_W = V' * X \n",
    "    \n",
    "        # update W \n",
    "        W .= W .* At_mul_B!(numerator_W, V, X) ./ A_mul_B!(denomenator_W, At_mul_B!(out_rr, V, V), W)  \n",
    "        \n",
    "        if abs(sum(abs2, X - A_mul_B!(mul_VW, V, W)) - L) / (L + 1) < tol\n",
    "            L = sum(abs2, X - A_mul_B!(mul_VW, V, W))\n",
    "            break\n",
    "        end\n",
    "\n",
    "        #if abs(vecnorm(X - A_mul_B!(mul_VW, V, W))^2 - L) / (L + 1) < tol\n",
    "         #   L = vecnorm(X - A_mul_B!(mul_VW, V, W))^2\n",
    "          #  break\n",
    "        #end\n",
    "        \n",
    "        # update norm \n",
    "        L = sum(abs2, X - A_mul_B!(mul_VW, V, W))\n",
    "        \n",
    "    end  \n",
    "    \n",
    "    # Output\n",
    "    return L, V, W\n",
    "end\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Database 1 from the MIT Center for Biological and Computational Learning (CBCL) reduces to a matrix  $X$  containing  $m=2,429$  gray-scale face images with  $n=19Ã—19=361$  pixels per face. Each image (row) is scaled to have mean and standard deviation 0.25.\n",
    "Read in the nnmf-2429-by-361-face.txt file, e.g., using readdlm() function, and display a couple sample images, e.g., using ImageView.jl package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMQAAADBCAYAAACQax/YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEexJREFUeJzt3X9sVOWaB/Dv/GhPp6VOqS0zHaClhVINQrnCtrLgqktjIVkiiZso181W1ujGK7shjSGSCBUk2wiJaVCWJiYG+Acx2QvZxLuYaxXY3Vuqouj1rlTAem1tZ2hLf82UdjozZ/8gjG9h3mdonTqH6/eTTELnmffMy2mfns5zznlem2maJogIAGBP9wSIrIQJQaRgQhApmBBECiYEkYIJQaRgQhApmBBECiYEkYIJQaRgQhApnOmewM1isRi6u7uRm5sLm82W7unQHco0TYyMjMDn88Fun8LvfXOGvPnmm2ZJSYlpGIZZVVVltrW13da4zs5OEwAffKTk0dnZOaWf2xk5Qhw7dgz19fVobm5GdXU1mpqaUFtbi/b2dsyZM0ccm5ubCwB4cHk9nA4j4Wv6Kmdpxw8sjYrbX7SoR4zfZYxpY1fHssWxS/O6xfia3G+0sfuNXnFsMmfG5ovxf/t8vT4YyBLHFn5iivHs3rA2dvWeJNv+PCjG7aMT2lj064vaWAQT+B/8Lv7zdLtmJCFef/11PPvss9i8eTMAoLm5Ge+99x7efvttvPTSS+LYG38mOR0GnI7EO9ORqd/JdpecEM6cxEl2Q4YR04/VJOgNxqwMMZ6d69DGco2f9nHO5ZS/lfZs4QczS/6hdWbICeF06ucufa8AwOmIiHG7Q79tm03Y3+aN10ztz+6Uf6gOh8M4d+4campqfnwTux01NTVobW295fXj4+MYHh6e9CBKl5QnRF9fH6LRKDwez6TnPR4P/H7/La9vbGyE2+2OP+bPlw/9RDMp7WXX7du3Y2hoKP7o7OxM95ToFyzlnyEKCgrgcDgQCAQmPR8IBOD1em95vWEYMAz5b3Oin0vKjxCZmZlYsWIFWlpa4s/FYjG0tLRg1apVqX47opSakSpTfX096urqsHLlSlRVVaGpqQmhUChedbotX10GNFWEOeEy7TBj0C1u9uon8mcU2x/1ZcCsnqvi2DOPVovx389+QBsbWawvLwLAXy35Vox/2e0T4wt/fV6MS5xejxiP+APaWOFpedty/QqQaob2bH0Z3G6GgdEkG09gRhLiiSeeQG9vL3bu3Am/34/ly5fj5MmTt3zQJrKaGbt0Y8uWLdiyZctMbZ5oRqS9ykRkJUwIIgUTgkjBhCBSWO5+iBtsDjtstsQXw5kX9CXI3C/Gxe3aK+8V47EvvtbG5MvQgPy3fxDjA3X68zD5+rcFAPzD3956HZiq8d//Ud6AwFm2QIxHf5CvEJY4Zs+Wtz0wIMal0mpsVF9XjZlyGVv7ftMaRfQXiglBpGBCECmYEEQKJgSRgglBpGBCECksex4iNnoNMVuyyv/UXdii79gBAIuf1cfMVZXiWMeovvsEABR8qr98PJLnEsdu/d9NYnzumHwh9UTNCm3su4czxbHt/3RCjNf6lmtjyc4zJCOda4Bd37QBZgzQ94vQb3LqQ4j+cjEhiBRMCCIFE4JIwYQgUjAhiBRMCCKFZc9DOIvnwmlP3MAs8ufpd/e79/VBMR5+5H5tLJop//6wf3ZBjs/O08Yygsl6pshd08fy5Lll//acNrawp0Ice1/wN2K8uPzWFqVxgT5xbPQn9PJ1zMrRxkwzDExj0zxCECmYEEQKJgSRgglBpGBCECmYEESKlJddX3nlFezatWvScxUVFbhwQS5J3szMyIDpSNz921FYqB0X7ZUXL7SNJClvevWL9GUMy61NHIUFYjy0TN+hO+dLecFGm0O+ljmSPf0ljKN/ahfjJUNz5fGF+nIy8krEsY6gfpFLALANTK8sa4s5plV2nZHzEEuWLMEHH3zw45skWRCQyCpm5CfV6XQmXC2IyOpm5DPExYsX4fP5UFZWhqeeegrff//9TLwNUcql/AhRXV2NQ4cOoaKiAj09Pdi1axcefPBBfPXVVwkX0R4fH8f4+I/tJ7ksL6VTyhNi/fr18X8vW7YM1dXVKCkpwbvvvotnnnnmltc3Njbe8iGcKF1mvOyal5eHxYsX49KlSwnjXJaXrGTGEyIYDOLy5csoKipKGDcMA3fdddekB1G6pPxPphdffBEbNmxASUkJuru70dDQAIfDgU2b5DYqN+t8zAOHkZUw5jutP1dw7UH9CqUAMDJPaF0CwDGub+cSdsu1fldA37odAEJz9eNzLiQ+53KD7Yq8lrf722TnSPTnbkyffP6k56+F8wwAQsJpiqx+eZ9FXPrvJQDM/y+5RY5ONDoO6BdH1Up5QnR1dWHTpk3o7+9HYWEh1qxZg7Nnz6JQ+IYQWUXKE+Kdd95J9SaJfja8lolIwYQgUjAhiBRMCCIFE4JIYdnrskdLJ2B3JT5nEOzQt46/ukSue4eL5WV75xXpW9Y7IvLuiv6nXM83BoSW9dGoODaWIbe7Hy2U52YI94lcW10qjk0mWnZNGxsulM+vZPbK8x4t0beaGS3Qn1OKhseAL8RNJ8QjBJGCCUGkYEIQKZgQRAomBJGCCUGksGzZNaPfCXtW4uldeUxf5sMP8mqeUlkVADIc+vJn1JRLusNytxYUnhdayUTlNjPzKq6I8cE/J77f5HaMueVL4gfvk+eW6dTvs/uXyDd8fTeUL8avxPSl7Iyg/vsRHZ9eWx4eIYgUTAgiBROCSMGEIFIwIYgUTAgiBROCSGHd8xDDNjg0teSJb/XnGibmhcXtupxyu5YFuf3a2Ka728Sx/3LtSTGec1xfGx9ZKZ/E+OcF/yHGGzOeEOM2Q9/GZqxArtk/tOL/xPhETH8eo2NYPs8QvCa314nJV4+nHI8QRAomBJGCCUGkYEIQKZgQRAomBJGCCUGkmPJ5iDNnzmDfvn04d+4cenp6cPz4cWzcuDEeN00TDQ0NeOuttzA4OIjVq1fj4MGDKC8vn9L7uHpNODITt14Zu1s/ztkjt0//JiYvBtk9W78+xb/O+VAcW363vCTw2HcRbcwsXSyOXW50ifFwZUiMS2Z1yfc7bC86KcbrO/5eGxubkH/ErvXL96/MGtCfI5HmHZ2Q/086Uz5ChEIhVFZW4sCBAwnje/fuxf79+9Hc3Iy2tjbk5OSgtrYWY2PyesREVjDlI8T69esnrSOnMk0TTU1NePnll/HYY48BAI4cOQKPx4MTJ07gySflM7lE6ZbSzxAdHR3w+/2oqamJP+d2u1FdXY3W1taEY8bHxzE8PDzpQZQuKU0Iv98PAPB4PJOe93g88djNGhsb4Xa744/58+enckpEU5L2KhNXISUrSWlCeL3XKziBwOTV7gKBQDx2M65CSlaS0oQoLS2F1+tFS0tL/Lnh4WG0tbVh1apVqXwrohkx5SpTMBictAh7R0cHzp8/j/z8fBQXF2Pr1q3Ys2cPysvLUVpaih07dsDn8006V3FbExs14ZxIfB7C1avP44hc1kasX77APjihb7/+fPuvxbFSTycAMJz6flLZv5XvtXg6r16Ml/0xKMbNcf0yAFn98j0if/eH34jx1aXfamOdg/KSvhlX5R9BU/iVHc0Q+jIl6aGlM+WE+PTTT/HII4/Ev66vv/6Nqqurw6FDh7Bt2zaEQiE899xzGBwcxJo1a3Dy5ElkZSVec5rISqacEA8//DBMU794h81mw+7du7F79+6fNDGidEh7lYnISpgQRAomBJGCCUGksGwbmrDbhmhm4tJZTJi1Q15kFGM+/SXYADB/QZ82dmVoljg20qkv2QJA2WL9Fb/OiDyv2e3CEgAAwm75snep2Oy6KLfa9x6TW+3/YeV92ljByoA2BgBBl7y6anRseuXT6eIRgkjBhCBSMCGIFEwIIgUTgkjBhCBSMCGIFJY9D5H7/QSczsRt1qOGvuZuyivMwn5NfkHgE32bGt9/y5dJu1rltvG2u3K1sZGH5DY91/LledvkK8/hfuhX2ljsk3Zx7KwPh8R47qf6/9e1e+S2P8YD8u/kDKG7zqwf9EsfRCLysgg6PEIQKZgQRAomBJGCCUGkYEIQKZgQRAomBJHCsuchsr+5Aqc98ZKtIe887bjQXPn6+ZxO+XfAvN8JLe39+nslAGDiVwvFeN9SfY+coXvlEwmmXY5nDMrnKcJu/Xt7R+V524Jy5/bI1xe1MVey+zxmLxDjQwv1/y/XhcTtUQEgEktyY4wGjxBECiYEkYIJQaRgQhApmBBECiYEkSLlq5A+/fTTOHz48KQxtbW1OHlSXsnyZtFAH2y2xM1Tsnv1lxSP58vdvfMuymVA27j+Eu/IwIA41n5ajs85rY8VJVkXI1lJN+PzC2I8KixVJjeCAZJcWS6PHRgU46EiuVycOaSfXaTrB33MlC/V10n5KqQAsG7dOvT09MQfR48endbkiH5uKV2F9AbDMLQrBhFZ2Yx8hjh16hTmzJmDiooKPP/88+jv79e+lquQkpWkPCHWrVuHI0eOoKWlBa+99hpOnz6N9evXIxpN/JcoVyElK0n5tUzq4uxLly7FsmXLsHDhQpw6dQpr16695fXbt2+Pr0IEXF+TjklB6TLjZdeysjIUFBRMWpdOxVVIyUpmPCG6urrQ39+PoiK5gzSRFaR0FdL8/Hzs2rULjz/+OLxeLy5fvoxt27Zh0aJFqK2tndL7OPLccNgTt5vJbk18tAGAoO8ecbshr1z3zv5Qbg0/U6TzBADgOCu3uIkKq4z+VCNPPCDGM0Ixbczol+c1tEQ+X+A9naSvUIqldBXSgwcP4ssvv8Thw4cxODgIn8+HRx99FK+++ioMI/G9DURWkvJVSN9///2fNCGidOK1TEQKJgSRgglBpGBCECmYEEQKy7ahiQ4Oae+HMIWae45fvnp/oEL+L0cr9W3pY1lyTXwiR952Rkh/L8bgQrksnazNf9ZV/bkAAIhl6NvzzP5Cvo9j1CP/3nQJ3XkcY/I+MQJy3P319O/jmA4eIYgUTAgiBROCSMGEIFIwIYgUTAgihWXLrub4OEybXEpMxPX7L8R4Tpt8A9JYZbE21rNaLo26rsiFQFefvvSZ3SeXizOH5PY5EZdcl83qGdXG/H+TL46d3S6v6Bmcq2/9Y/Tq3xcAfGfEMMzP/yS/IMV4hCBSMCGIFEwIIgUTgkjBhCBSMCGIFJYru964XzuCiWldzmgz5Ry3x+QSYiSiX2AwOiZPKBqW45EJfRnZnJDH2pMsXhiZkMuukaj+CuFoOMmiihG5M0Y0rC8ZS+97fdvy98s2zS7eEVwfJ93/n/j9pjpihnV1dbFzH6VMZ2cn5s3Tr1p7M8slRCwWQ3d3N3Jzc2Gz2eKtLTs7O9nV7zZxn10/MoyMjMDn88Fuv/1PBpb7k8lutyfMaLa5nLpf+j5zu91THsMP1UQKJgSRwvIJYRgGGhoa2ApzCrjPps9yH6qJ0snyRwiinxMTgkjBhCBSMCGIFJZPiAMHDmDBggXIyspCdXU1Pv7443RPyTLOnDmDDRs2wOfzwWaz4cSJE5Pipmli586dKCoqgsvlQk1NDS5evJim2d4ZLJ0Qx44dQ319PRoaGvDZZ5+hsrIStbW1uHIlPcteWU0oFEJlZSUOHDiQML53717s378fzc3NaGtrQ05ODmprazE2Jl/M94tmWlhVVZX5wgsvxL+ORqOmz+czGxsb0zgrawJgHj9+PP51LBYzvV6vuW/fvvhzg4ODpmEY5tGjR9MxxTuCZY8Q4XAY586dQ01NTfw5u92OmpoatLa2pnFmd4aOjg74/f5J+8/tdqO6upr7T2DZhOjr60M0GoXH45n0vMfjgd/vT9Os7hw39hH339RYNiGI0sGyCVFQUACHw4FAIDDp+UAgAK/Xm6ZZ3Tlu7CPuv6mxbEJkZmZixYoVaGlpiT8Xi8XQ0tKCVatWpXFmd4bS0lJ4vd5J+294eBhtbW3cfwLL3SCkqq+vR11dHVauXImqqio0NTUhFAph8+bN6Z6aJQSDQVy6dCn+dUdHB86fP4/8/HwUFxdj69at2LNnD8rLy1FaWoodO3bA5/Nh48aNaZy1xaW7zJXMG2+8YRYXF5uZmZlmVVWVefbs2XRPyTI++ugjE9dbMUx61NXVmaZ5vfS6Y8cO0+PxmIZhmGvXrjXb29vTO2mL4+XfRArLfoYgSgcmBJGCCUGkYEIQKZgQRAomBJGCCUGkYEIQKZgQRAomBJGCCUGkYEIQKf4fXn8yB2QQlXEAAAAASUVORK5CYII=",
      "text/plain": [
       "PyPlot.Figure(PyObject <matplotlib.figure.Figure object at 0x000000002B6CA898>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.image.AxesImage object at 0x000000002B0942E8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add package for visulizating image\n",
    "#Pkg.add(\"ImageView\")\n",
    "#Pkg.add(\"Images\")\n",
    "#Pkg.add(\"TestImages\")\n",
    "#Pkg.build(\"Cairo\")\n",
    "#Pkg.pin(\"Cairo\", v\"0.4.0\")\n",
    "#Pkg.update()\n",
    "#Pkg.add(\"PyPlot\")\n",
    "using ImageView, Images, PyPlot\n",
    "\n",
    "# readin matrix file\n",
    "path_X = \"http://Hua-Zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/nnmf-2429-by-361-face.txt\"\n",
    "\n",
    "X = readdlm(download(path_X), ' ')\n",
    "\n",
    "# randomly show six face images\n",
    "# extract one row pixels to form one face image\n",
    "img1 = reshape(X[10, :], 19, 19)\n",
    "img2 = reshape(X[20, :], 19, 19)\n",
    "img3 = reshape(X[9, :], 19, 19)\n",
    "img4 = reshape(X[75, :], 19, 19)\n",
    "img5 = reshape(X[321, :], 19, 19)\n",
    "img6 = reshape(X[99, :], 19, 19)\n",
    "\n",
    "subplot(231)\n",
    "PyPlot.imshow(img)\n",
    "\n",
    "subplot(232)\n",
    "PyPlot.imshow(img)\n",
    "\n",
    "subplot(233)\n",
    "PyPlot.imshow(img)\n",
    "\n",
    "subplot(234)\n",
    "PyPlot.imshow(img)\n",
    "\n",
    "subplot(235)\n",
    "PyPlot.imshow(img)\n",
    "\n",
    "subplot(236)\n",
    "PyPlot.imshow(img)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Report the run times, using `@time`, of your function for fitting NNMF on the MIT CBCL face data set at ranks $r=10, 20, 30, 40, 50$. For ease of comparison (and grading), please start your algorithm with the provided $\\mathbf{V}^{(0)}$ (first $r$ columns of [`V0.txt`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/V0.txt)) and $\\mathbf{W}^{(0)}$ (first $r$ rows of [`W0.txt`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/W0.txt)) and stopping criterion\n",
    "$$\n",
    "\t\\frac{|L^{(t+1)} - L^{(t)}|}{|L^{(t)}| + 1} \\le 10^{-4}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2429Ã—361 Array{Float64,2}:\n",
       " 0.14815    0.018294   0.027569   0.0        â€¦  0.0       0.0       0.0      \n",
       " 0.20667    0.095859   0.0020948  0.10438       0.0       0.0       0.0      \n",
       " 0.020835   0.0        0.13617    0.0030917     0.0       0.0       0.0      \n",
       " 0.0        0.25467    0.0        0.076619      0.14222   0.020391  0.0      \n",
       " 0.0082034  0.0        0.16066    0.0           0.089516  0.059024  0.0      \n",
       " 0.0        0.0        0.0        0.32852    â€¦  0.21551   0.11192   0.027156 \n",
       " 0.0        0.0        0.0        0.027593      0.28612   0.26544   0.14135  \n",
       " 0.16249    0.15444    0.0095702  0.0           0.33151   0.33956   0.35566  \n",
       " 0.090691   0.11932    0.1408     0.04774       0.34839   0.32692   0.29828  \n",
       " 0.0        0.069167   0.098722   0.1135        0.34994   0.36472   0.32778  \n",
       " 0.1602     0.0060618  0.0        0.0        â€¦  0.42994   0.42994   0.37214  \n",
       " 0.02756    0.0        0.11518    0.0           0.045083  0.018798  0.0012747\n",
       " 0.22345    0.0021421  0.0        0.044701      0.044701  0.027678  0.019166 \n",
       " â‹®                                           â‹±                      â‹®        \n",
       " 0.15922    0.17035    0.064602   0.0089446     0.11469   0.086866  0.0033788\n",
       " 0.0        0.0        0.037896   0.043361      0.0       0.0       0.0      \n",
       " 0.15336    0.11318    0.079692   0.0           0.046206  0.026114  0.0      \n",
       " 0.2064     0.13341    0.04714    0.0        â€¦  0.086955  0.067048  0.0      \n",
       " 0.0        0.0        0.0        0.0           0.0       0.0       0.0      \n",
       " 0.02175    0.16895    0.19282    0.10927       0.1411    0.12519   0.10529  \n",
       " 0.053085   0.14702    0.22053    0.11026       0.14293   0.11843   0.049001 \n",
       " 0.0        0.21869    0.27531    0.14588       0.085213  0.073079  0.0      \n",
       " 0.0        0.040962   0.13268    0.14066    â€¦  0.12072   0.076853  0.021023 \n",
       " 0.0        0.010794   0.15355    0.11277       0.125     0.088292  0.018951 \n",
       " 0.0        0.067969   0.2094     0.20132       0.16899   0.11646   0.0      \n",
       " 0.0        0.0        0.0        0.0           0.2962    0.2268    0.17908  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# readin matrix V0\n",
    "path_V0 = \"http://Hua-Zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/V0.txt\"\n",
    "V0 = readdlm(download(path_V0), ' ')\n",
    "\n",
    "# readin matrix W0\n",
    "path_W0 = \"http://Hua-Zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/W0.txt\"\n",
    "W0 = readdlm(download(path_W0), ' ')\n",
    "\n",
    "# readin matrix file\n",
    "path_X = \"http://Hua-Zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/nnmf-2429-by-361-face.txt\"\n",
    "\n",
    "X = readdlm(download(path_X), ' ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11729.228557363946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11729.228557363946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11729.228557363946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.265322 seconds (982 allocations: 3.136 GiB, 11.87% gc time)\n",
      "  0.036693 seconds (30 allocations: 27.188 MiB, 17.38% gc time)\n"
     ]
    }
   ],
   "source": [
    "# when r = 10\n",
    "V = V0[:, 1:10]\n",
    "W = W0[1:10, :]\n",
    "\n",
    "#@time nnmf(X, 10, maxiter = 1000, tol = 1e-4, V = V0, W = W0)\n",
    "@time L1, V1, W1 = nnmf(X, 10, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "@time L1, V1, W1 = nnmf(X, 10, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "display(L1)\n",
    "display(sum(abs2, X - V1*W1))\n",
    "display(vecnorm(X-V1*W1)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.259674 seconds (30 allocations: 27.616 MiB, 51.29% gc time)\n",
      "  0.078556 seconds (30 allocations: 27.616 MiB, 22.81% gc time)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4367.291708829291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25625.806241447288"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when r = 20\n",
    "V = V0[:, 1:20]\n",
    "W = W0[1:20, :]\n",
    "\n",
    "@time L2, V2, W2 = nnmf(X, 20, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "@time L2, V2, W2 = nnmf(X, 20, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "\n",
    "sum(abs2, X - V2*W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216.16966877462207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12.410618 seconds (1.96 k allocations: 6.312 GiB, 7.84% gc time)\n",
      "  0.038009 seconds (30 allocations: 28.045 MiB, 10.60% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6620.970037755855"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when r = 30\n",
    "V = V0[:, 1:30]\n",
    "W = W0[1:30, :]\n",
    "\n",
    "@time L3, V3, W3 = nnmf(X, 30, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "@time L3, V3, W3 = nnmf(X, 30, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "\n",
    "display(norm(X -V3*W3)^2)\n",
    "sum(abs2, X - V3*W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142.86635568547197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16.921407 seconds (2.35 k allocations: 7.606 GiB, 6.64% gc time)\n",
      "  0.040456 seconds (30 allocations: 28.476 MiB, 10.10% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5256.143033035294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when r = 40\n",
    "V = V0[:, 1:40]\n",
    "W = W0[1:40, :]\n",
    "\n",
    "@time L4, V4, W4 = nnmf(X, 40, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "@time L4, V4, W4 = nnmf(X, 40, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "\n",
    "display(norm(X -V4*W4)^2)\n",
    "sum(abs2, X - V4*W4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22.952833 seconds (2.82 k allocations: 9.136 GiB, 5.90% gc time)\n",
      "  0.047515 seconds (31 allocations: 28.909 MiB, 11.38% gc time)\n"
     ]
    }
   ],
   "source": [
    "# when r = 50\n",
    "V = V0[:, 1:50]\n",
    "W = W0[1:50, :]\n",
    "\n",
    "@time L5, V5, W5 = nnmf(X, 50, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "@time L5, V5, W5 = nnmf(X, 50, maxiter = 1000, tol = 1e-4, V = V, W = W);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Choose an $râˆˆ{10,20,30,40,50}$  and start your algorithm from a different $V(0)$  and  $W(0)$ . Do you obtain the same objective value and  $(V,W)$ ? Explain what you find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Choose $r = 10$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26361.94193212586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25984.0874695548"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10Ã—361 Array{Float64,2}:\n",
       " 0.289964   0.375533   0.0336859   â€¦  0.630697   0.550657   0.106138 \n",
       " 0.141391   0.202895   0.00414434     0.104091   0.57677    0.28918  \n",
       " 0.185356   0.296642   0.555991       0.456119   0.104223   0.445072 \n",
       " 0.0155426  0.24416    0.183652       0.0193073  0.489833   0.159693 \n",
       " 0.304673   0.0623813  0.519545       0.352486   0.563425   0.302205 \n",
       " 0.297589   0.229089   0.249258    â€¦  0.520951   0.297329   0.272805 \n",
       " 0.225845   0.383152   0.0953733      0.511265   0.167999   0.167488 \n",
       " 0.27272    0.144465   0.490755       0.0366766  0.0930852  0.118944 \n",
       " 0.214453   0.0769999  0.319755       0.102446   0.0312846  0.0262098\n",
       " 0.0115418  0.386969   0.214236       0.578223   0.0994848  0.366955 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10Ã—361 Array{Float64,2}:\n",
       " 0.221319   0.16758    0.0374999   â€¦  0.363318   0.101537    0.0825558\n",
       " 0.265562   0.138101   0.0498227      0.165129   0.23274     0.227002 \n",
       " 0.0199433  0.0237087  0.403445       0.494061   0.123564    0.403017 \n",
       " 0.288523   0.0716816  0.00347524     0.348261   0.00980486  0.329232 \n",
       " 0.20881    0.186709   0.32856        0.0629387  0.448063    0.302759 \n",
       " 0.0561138  0.42171    0.101862    â€¦  0.667475   0.614718    0.253254 \n",
       " 0.0895907  0.438507   0.391475       0.0127086  0.476733    0.0855468\n",
       " 0.360298   0.478382   0.47052        0.381805   0.37578     0.240452 \n",
       " 0.299134   0.172603   0.476445       0.505627   0.479491    0.291251 \n",
       " 0.140716   0.312547   0.388696       0.261901   0.0520511   0.0108949"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V = V0[:, 41:50]\n",
    "W = W0[41:50, :]\n",
    "\n",
    "L6, V6, W6 = nnmf(X, 10, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "display(L6)\n",
    "display(L1)\n",
    "display(L1 == L6)\n",
    "display(V1 == V6)\n",
    "display(W1 == V6)\n",
    "sum(abs2, X - V6*W6)\n",
    "vecnorm(X - V*W)^2\n",
    "display(W6)\n",
    "display(W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 For the same  $r$ , start your algorithm from  $v(0)_{ik}=w(0)_{kj}=1$  for all  $i,j,k$ . Do you obtain the same objective value and  $(V,W)$ ? Explain what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25570.62192539284"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25984.0874695548"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10Ã—361 Array{Float64,2}:\n",
       " 0.371818  0.461966  0.514894  0.482519  â€¦  0.639864  0.571488  0.438445\n",
       " 0.371818  0.461966  0.514894  0.482519     0.639864  0.571488  0.438445\n",
       " 0.371818  0.461966  0.514894  0.482519     0.639864  0.571488  0.438445\n",
       " 0.371818  0.461966  0.514894  0.482519     0.639864  0.571488  0.438445\n",
       " 0.371818  0.461966  0.514894  0.482519     0.639864  0.571488  0.438445\n",
       " 0.371818  0.461966  0.514894  0.482519  â€¦  0.639864  0.571488  0.438445\n",
       " 0.371818  0.461966  0.514894  0.482519     0.639864  0.571488  0.438445\n",
       " 0.371818  0.461966  0.514894  0.482519     0.639864  0.571488  0.438445\n",
       " 0.371818  0.461966  0.514894  0.482519     0.639864  0.571488  0.438445\n",
       " 0.371818  0.461966  0.514894  0.482519     0.639864  0.571488  0.438445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10Ã—361 Array{Float64,2}:\n",
       " 0.221319   0.16758    0.0374999   â€¦  0.363318   0.101537    0.0825558\n",
       " 0.265562   0.138101   0.0498227      0.165129   0.23274     0.227002 \n",
       " 0.0199433  0.0237087  0.403445       0.494061   0.123564    0.403017 \n",
       " 0.288523   0.0716816  0.00347524     0.348261   0.00980486  0.329232 \n",
       " 0.20881    0.186709   0.32856        0.0629387  0.448063    0.302759 \n",
       " 0.0561138  0.42171    0.101862    â€¦  0.667475   0.614718    0.253254 \n",
       " 0.0895907  0.438507   0.391475       0.0127086  0.476733    0.0855468\n",
       " 0.360298   0.478382   0.47052        0.381805   0.37578     0.240452 \n",
       " 0.299134   0.172603   0.476445       0.505627   0.479491    0.291251 \n",
       " 0.140716   0.312547   0.388696       0.261901   0.0520511   0.0108949"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = ones(2429, 10)\n",
    "W = ones(10, 361)\n",
    "L7, V7, W7 = nnmf(X, 10, maxiter = 1000, tol = 1e-4, V = V, W = W);\n",
    "display(L7)\n",
    "display(L1)\n",
    "display(W7)\n",
    "W1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 Plot the basis images (rows of  $W$ ) at rank  $r=50$ . What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:50\n",
    "    # extract one row pixels in Wto form one face image\n",
    "    img = reshape(W5[i, :], 19, 19)\n",
    "    imshow(img)\n",
    "end  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The images of the rows in W shows the parts of the faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 Linear Mixed Models\n",
    "\n",
    "Consider a linear mixed effects model\n",
    "$$\n",
    "\ty_i = \\mathbf{x}_i^T \\beta + \\mathbf{z}_i^T \\gamma + \\epsilon_i, \\quad i=1,\\ldots,n,\n",
    "$$\n",
    "where $\\epsilon_i$ are independent normal errors $N(0,\\sigma_0^2)$, $\\beta \\in \\mathbb{R}^p$ are fixed effects, and $\\gamma \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\sigma_1^2 \\mathbf{I}_q$) independent of $\\epsilon_i$. \n",
    "\n",
    "0. Show that \n",
    "$$\n",
    "    \\mathbf{y} \\sim N \\left( \\mathbf{X} \\beta, \\sigma_0^2 \\mathbf{I}_n + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T \\right),\n",
    "$$\n",
    "where $\\mathbf{y} = (y_1, \\ldots, y_n)^T \\in \\mathbb{R}^n$, $\\mathbf{X} = (\\mathbf{x}_1, \\ldots, \\mathbf{x}_n)^T \\in \\mathbb{R}^{n \\times p}$, and $\\mathbf{Z} = (\\mathbf{z}_1, \\ldots, \\mathbf{z}_n)^T \\in \\mathbb{R}^{n \\times q}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\because Y = \\mathbf{X} \\beta + \\mathbf{Z} \\gamma + \\epsilon_i \\\\\n",
    "\\therefore \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Let $\\mathbf{X} = (\\mathbf{x}_1, \\ldots, \\mathbf{x}_n)^T \\in \\mathbb{R}^{n \\times p}$\n",
    "$$\n",
    "\\begin{align}\n",
    "    E(\\mathbf{y}) &= E(\\mathbf{X} \\beta + \\mathbf{Z} \\gamma + \\epsilon_i) \\\\\n",
    "    &= E(\\mathbf{X} \\beta) + E(\\mathbf{Z} \\gamma) + E(\\epsilon_i) \\\\\n",
    "    &= \\mathbf{X} E(\\beta) + \\mathbf{Z} E(\\gamma) + E(\\epsilon_i) \\\\\n",
    "    &= \\mathbf{X} \\beta + 0 + 0 \\\\\n",
    "    &= \\mathbf{X} \\beta\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Let $\\mathbf{Z} = (\\mathbf{z}_1, \\ldots, \\mathbf{z}_n)^T \\in \\mathbb{R}^{n \\times q}$ \n",
    "\n",
    "Assuming $\\beta$, $\\gamma$, and $\\epsilon$ are independent, then \n",
    "$$\n",
    "\\begin{align}\n",
    "    Var(\\mathbf{y}) &= Var(\\mathbf{X} \\beta + \\mathbf{Z} \\gamma + \\epsilon_i) \\\\\n",
    "    &= Var(\\mathbf{X} \\beta) + Var(\\mathbf{Z} \\gamma) + Var(\\epsilon_i) \\\\\n",
    "    &= 0 + Var(\\mathbf{Z} \\gamma) + Var(\\epsilon_i) \\\\\n",
    "    &= \\mathbf{Z} Var(\\gamma) \\mathbf{Z}^T + \\sigma_0^2 \\\\\n",
    "    &= \\mathbf{Z} \\sigma_1^2 \\mathbf{I}_q \\mathbf{Z}^T + \\sigma_0^2 \\\\\n",
    "    &= \\sigma_0^2 \\mathbf{I}_n + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore $\\mathbf{y} \\sim N \\left( \\mathbf{X} \\beta, \\sigma_0^2 \\mathbf{I}_n + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T \\right)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
