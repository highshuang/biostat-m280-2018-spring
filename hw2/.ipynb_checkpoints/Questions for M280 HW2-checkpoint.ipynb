{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "* My first question is about the input define for function in general. Because after I run the nnmf function, the error: X undefined shows up. Below, the question is not about the main body of the function. I just want to show the error message here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: X not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: X not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:522\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "function nnmf(\n",
    " X::Matrix{Float64}, \n",
    " r::Int;\n",
    " maxiter::Int=2, \n",
    " tol::eltype(X)=1e-4,\n",
    " V::Matrix{eltype(X)}=rand(size(X, 1), r),\n",
    " W::Matrix{eltype(X)}=rand(r, size(X, 2))\n",
    " )  \n",
    "    # initilize two matrices \n",
    "    V_new = zeros(size(V))\n",
    "    W_new = zeros(size(W))\n",
    "    \n",
    "    for t in 1:maxiter # stop after 1000 iterations\n",
    "        # update v by element\n",
    "        for k in 1:r, i in 1:size(X, 1)\n",
    "            # initialize float number for denomenator\n",
    "            denomenator = 0.0\n",
    "            # update denomenator \n",
    "            for j in 1:size(X, 2)\n",
    "                denomenator += vecdot(V[i, :], W[:, j]) * W[k, j]\n",
    "            end\n",
    "            # update element V_ik\n",
    "            V_new[i, k] = V[i, k] * vecdot(X[i, :], W[k, :]) / denomenator \n",
    "        end\n",
    "\n",
    "\n",
    "        \n",
    "        # update W by element\n",
    "        for j in 1:size(X, 2), k in 1:r\n",
    "            # initialize float number for denomenator\n",
    "            denomenator = 0.0\n",
    "            # update denomenator \n",
    "            for i in 1:size(X, 1)\n",
    "                denomenator += vecdot(V_new[i, :], W[:, j]) * V_new[i, k]\n",
    "            end\n",
    "            # update element W_kj\n",
    "            W_new[k, j] = W[k, j] * vecdot(X[:, j], V_new[:, k]) / denomenator \n",
    "        end\n",
    "        \n",
    "        # update V W \n",
    "        V = copy(V_new)\n",
    "        W = copy(W_new) \n",
    "        \n",
    "        # calculate Frobenius norm after each iteration\n",
    "        norm = 0.0\n",
    "        for j = 1:size(X, 2), i = 1:size(X, 1)\n",
    "            norm += (X[i, j] - vecdot(V[i, :], W[:, j]))^2 \n",
    "        end\n",
    "    \n",
    "        # exit loop if norm less than tolerance\n",
    "        if norm <= tol\n",
    "            exit \n",
    "        end\n",
    "    end      \n",
    "    \n",
    "    # Output\n",
    "    return V, W\n",
    "end\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below I try to remove the main body of the function, but the error still shows up. Probably the problem is `V::Matrix{eltype(X)}=rand(size(X, 1), r)` is used X as input for matrix type, but we not acutually having X right now. But I am not sure how to fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: X not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: X not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:522\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "function nnmf(\n",
    " X::Matrix{Float64}, \n",
    " r::Int;\n",
    " maxiter::Int=2, \n",
    " tol::eltype(X)=1e-4,\n",
    " V::Matrix{eltype(X)}=rand(size(X, 1), r),\n",
    " W::Matrix{eltype(X)}=rand(r, size(X, 2))\n",
    " )  \n",
    "    # simple main body to check the function\n",
    "    V = zeros(1, 1)\n",
    "    W = zeros(1, 1)    \n",
    "    \n",
    "    # Output\n",
    "    return V, W\n",
    "end\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to run the function, I remove the tol, V, W input and manually import the matrix in the beginning of the function. But I don't think this is the right way to solve the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnmf_1 (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nnmf_1(\n",
    " X::Matrix, \n",
    " r::Int;\n",
    " maxiter::Int = 1000, \n",
    " tol::Float64 = 1e-4\n",
    " )  \n",
    "    # readin matrix V0\n",
    "    path_V0 = \"http://Hua-Zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/V0.txt\"\n",
    "    V0 = readdlm(download(path_V0), ' ')\n",
    "\n",
    "    # readin matrix W0\n",
    "    path_W0 = \"http://Hua-Zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/W0.txt\"\n",
    "    W0 = readdlm(download(path_W0), ' ')\n",
    "\n",
    "    V = V0[:, 1:r]\n",
    "    W = W0[1:r, :]\n",
    "    \n",
    "    \n",
    "    # input V W \n",
    "    #V = rand(size(X, 1), r)\n",
    "    #W = rand(r, size(X, 2))\n",
    "    \n",
    "    # initilize two matrices \n",
    "    V_new = zeros(size(V))\n",
    "    W_new = zeros(size(W))\n",
    "    \n",
    "    for t in 1:maxiter # stop after 1000 iterations\n",
    "        # update v by element\n",
    "        for k in 1:r, i in 1:size(X, 1)\n",
    "            # initialize float number for denomenator\n",
    "            denomenator = 0.0\n",
    "            # update denomenator \n",
    "            for j in 1:size(X, 2)\n",
    "                denomenator += dot(V[i, :], W[:, j]) * W[k, j]\n",
    "            end\n",
    "            # update element V_ik\n",
    "            V_new[i, k] = V[i, k] * vecdot(X[i, :], W[k, :]) / denomenator \n",
    "        end\n",
    "\n",
    "\n",
    "        \n",
    "        # update W by element\n",
    "        for j in 1:size(X, 2), k in 1:r\n",
    "            # initialize float number for denomenator\n",
    "            denomenator = 0.0\n",
    "            # update denomenator \n",
    "            for i in 1:size(X, 1)\n",
    "                denomenator += vecdot(V_new[i, :], W[:, j]) * V_new[i, k]\n",
    "            end\n",
    "            # update element W_kj\n",
    "            W_new[k, j] = W[k, j] * vecdot(X[:, j], V_new[:, k]) / denomenator \n",
    "        end\n",
    "        \n",
    "        # update V W \n",
    "        V = copy(V_new)\n",
    "        W = copy(W_new) \n",
    "        \n",
    "        # calculate Frobenius norm after each iteration\n",
    "        norm = 0.0\n",
    "        for j = 1:size(X, 2), i = 1:size(X, 1)\n",
    "            norm += (X[i, j] - vecdot(V[i, :], W[:, j]))^2 \n",
    "        end\n",
    "    \n",
    "        # exit loop if norm less than tolerance\n",
    "        if norm <= tol\n",
    "            exit \n",
    "        end\n",
    "    end      \n",
    "    \n",
    "    # Output\n",
    "    return V, W\n",
    "end\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **This part is related to the function, if you don't have time, I can talk to you on Monday during office hour**\n",
    "* Another thing I still did not figure out is my function takes forever to run. I change the maxiter = 2, there are some results. But after I change back to 1000, it does not work. Below shows the result for r = 10. May I have some hint for this problem?\n",
    "* After I use `@time` to see the memory allocation, I see a big problem here. For this algorithm, I think I have to initilize two matrices for updating V, W, because there is a $b_{ij}$ part, which needs the infomation from the previous V matrix. How should I improve the function?\n",
    "* Below I try profiling the code, the line with the most count number is line -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14.474627 seconds (340.27 M allocations: 15.496 GiB, 8.40% gc time)\n",
      " 13.940056 seconds (340.27 M allocations: 15.496 GiB, 7.70% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0597217 0.0189092 … 0.0457883 0.0568525; 0.0283231 0.0622263 … 0.0130065 0.0762958; … ; 0.0846051 0.0682364 … 0.0143376 0.0289061; 0.0997003 0.0963602 … 0.0815733 0.050848], [0.238528 0.21145 … 0.416089 0.206551; 0.254568 0.095235 … 0.0720512 0.310289; … ; 0.232507 0.148173 … 0.232909 0.184989; 0.141977 0.323308 … 0.0951747 0.281921])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# readin matrix X\n",
    "path_X = \"http://Hua-Zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/nnmf-2429-by-361-face.txt\"\n",
    "X = readdlm(download(path_X), ' ')\n",
    "\n",
    "@time nnmf(X,10, maxiter = 2, tol = 10.0^(-4))\n",
    "@time nnmf(X,10, maxiter = 2, tol = 10.0^(-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count File                        Line Function                               \n",
      "  5710 .\\<missing>                   -1 anonymous                              \n",
      "    75 .\\In[3]                        9 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "    19 .\\In[3]                       13 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "    14 .\\In[3]                       15 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "     3 .\\In[3]                       33 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "  2371 .\\In[3]                       34 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "    89 .\\In[3]                       37 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "     7 .\\In[3]                       47 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "  2653 .\\In[3]                       48 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "    40 .\\In[3]                       51 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "   439 .\\In[3]                       61 #nnmf#3(::Int64, ::Float64, ::Funct... \n",
      "     5 .\\abstractarray.jl           342 checkbounds                            \n",
      "    38 .\\abstractarray.jl           362 checkbounds                            \n",
      "     1 .\\abstractarray.jl           573 copy!(::Array{Any,1}, ::Core.Infere... \n",
      "     1 .\\abstractarray.jl           764 eachindex                              \n",
      "     2 .\\abstractarray.jl           883 getindex                               \n",
      "    10 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Colo... \n",
      "    56 .\\abstractarray.jl           883 getindex                               \n",
      "  1020 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     6 .\\abstractarray.jl           883 getindex                               \n",
      "     7 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "   994 .\\abstractarray.jl           883 getindex                               \n",
      "     9 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     3 .\\abstractarray.jl           883 getindex                               \n",
      "     2 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "   143 .\\abstractarray.jl           883 getindex                               \n",
      "     7 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     2 .\\abstractarray.jl           883 getindex                               \n",
      "     9 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     5 .\\abstractarray.jl           883 getindex                               \n",
      "     1 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     3 .\\abstractarray.jl           883 getindex                               \n",
      "    14 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     4 .\\abstractarray.jl           883 getindex                               \n",
      "     9 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     2 .\\abstractarray.jl           883 getindex                               \n",
      "     3 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "    25 .\\abstractarray.jl           883 getindex                               \n",
      "     6 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     1 .\\abstractarray.jl           883 getindex                               \n",
      "     4 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "    53 .\\abstractarray.jl           883 getindex                               \n",
      "    91 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     2 .\\abstractarray.jl           883 getindex                               \n",
      "     9 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "    11 .\\abstractarray.jl           883 getindex                               \n",
      "     5 .\\abstractarray.jl           883 getindex(::Array{Float64,2}, ::Int6... \n",
      "     1 .\\abstractarray.jl           883 getindex                               \n",
      "     1 .\\abstractarray.jl            71 indices1                               \n",
      "    36 .\\abstractarray.jl            64 indices                                \n",
      "    10 .\\abstractarray.jl           194 stride(::Array{Float64,1}, ::Int64)    \n",
      "     1 .\\array.jl                   396 _collect(::Type{Any}, ::Core.Infere... \n",
      "     1 .\\array.jl                   393 collect(::Type{Any}, ::Core.Inferen... \n",
      "    74 .\\array.jl                   555 getindex(::Array{Float64,2}, ::Int6... \n",
      "   158 .\\cartesian.jl                62 macro expansion                        \n",
      "   156 .\\cartesian.jl                64 macro expansion                        \n",
      "    84 .\\datafmt.jl                  73 #readdlm#6                             \n",
      "    84 .\\datafmt.jl                  81 #readdlm#7                             \n",
      "    84 .\\datafmt.jl                 134 #readdlm_auto#11(::Array{Any,1}, ::... \n",
      "    69 .\\datafmt.jl                 417 colval(::String, ::Int64, ::Int64, ... \n",
      "     1 .\\datafmt.jl                 418 colval(::String, ::Int64, ::Int64, ... \n",
      "    76 .\\datafmt.jl                 397 dlm_fill(::DataType, ::Array{Array{... \n",
      "     1 .\\datafmt.jl                 479 dlm_parse(::String, ::Char, ::Char,... \n",
      "     7 .\\datafmt.jl                 493 dlm_parse(::String, ::Char, ::Char,... \n",
      "    84 .\\datafmt.jl                  73 readdlm(::String, ::Char)              \n",
      "    84 .\\datafmt.jl                  81 readdlm(::String, ::Char, ::Char)      \n",
      "     8 .\\datafmt.jl                 343 readdlm_string(::String, ::Char, ::... \n",
      "    76 .\\datafmt.jl                 358 readdlm_string(::String, ::Char, ::... \n",
      "     4 .\\datafmt.jl                 178 store_cell(::Base.DataFmt.DLMOffset... \n",
      "     2 .\\datafmt.jl                 186 store_cell(::Base.DataFmt.DLMOffset... \n",
      "     1 .\\datafmt.jl                 236 store_cell(::Base.DataFmt.DLMStore{... \n",
      "     1 .\\datafmt.jl                 237 store_cell(::Base.DataFmt.DLMStore{... \n",
      "    70 .\\datafmt.jl                 268 store_cell(::Base.DataFmt.DLMStore{... \n",
      "     2 .\\datafmt.jl                 291 store_cell(::Base.DataFmt.DLMStore{... \n",
      "     1 .\\generator.jl                45 next(::Core.Inference.Generator{Arr... \n",
      "    24 .\\indices.jl                 233 Type                                   \n",
      "    24 .\\indices.jl                 213 to_indices                             \n",
      "     5 .\\indices.jl                 215 to_indices                             \n",
      "     1 .\\inference.jl              1897 abstract_call(::Any, ::Array{Any,1}... \n",
      "     1 .\\inference.jl              1420 abstract_call_gf_by_type(::Any, ::A... \n",
      "     2 .\\inference.jl              1950 abstract_eval(::Any, ::Array{Any,1}... \n",
      "     1 .\\inference.jl              1901 abstract_eval_call(::Expr, ::Array{... \n",
      "     1 .\\inference.jl              1927 abstract_eval_call(::Expr, ::Array{... \n",
      "     1 .\\inference.jl              3993 inlineable(::Any, ::Any, ::Expr, ::... \n",
      "     1 .\\inference.jl              4265 inlining_pass!(::Core.Inference.Inf... \n",
      "     1 .\\inference.jl              4327 inlining_pass(::Expr, ::Core.Infere... \n",
      "     1 .\\inference.jl              4428 inlining_pass(::Expr, ::Core.Infere... \n",
      "     1 .\\inference.jl              2905 optimize(::Core.Inference.Inference... \n",
      "     1 .\\inference.jl              2787 typeinf(::Core.Inference.InferenceS... \n",
      "     1 .\\inference.jl              2816 typeinf(::Core.Inference.InferenceS... \n",
      "     1 .\\inference.jl              2583 typeinf_code(::Core.MethodInstance,... \n",
      "     1 .\\inference.jl              2535 typeinf_edge(::Method, ::Any, ::Sim... \n",
      "     1 .\\inference.jl              2622 typeinf_ext(::Core.MethodInstance, ... \n",
      "     1 .\\inference.jl              2504 typeinf_frame(::Core.MethodInstance... \n",
      "     1 .\\inference.jl              2722 typeinf_work(::Core.Inference.Infer... \n",
      "     1 .\\inference.jl              2161 widenconst(::Core.Inference.Const)     \n",
      "    10 .\\interactiveutil.jl         595 download(::String, ::String)           \n",
      "     9 .\\linalg\\blas.jl             309 dot(::Array{Float64,1}, ::Array{Flo... \n",
      "   132 .\\linalg\\blas.jl             313 dot(::Array{Float64,1}, ::Array{Flo... \n",
      "  5711 .\\loading.jl                 522 include_string(::String, ::String)     \n",
      "  2469 .\\multidimensional.jl        491 _getindex                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   315 .\\multidimensional.jl        519 _unsafe_getindex!                      \n",
      "  1977 .\\multidimensional.jl        506 _unsafe_getindex(::IndexLinear, ::A... \n",
      "    39 .\\multidimensional.jl        494 macro expansion                        \n",
      "  2430 .\\multidimensional.jl        495 macro expansion                        \n",
      "    26 .\\multidimensional.jl        509 macro expansion                        \n",
      "  1461 .\\multidimensional.jl        511 macro expansion                        \n",
      "   132 .\\multidimensional.jl        512 macro expansion                        \n",
      "   315 .\\multidimensional.jl        513 macro expansion                        \n",
      "     1 .\\multidimensional.jl        523 macro expansion                        \n",
      "   314 .\\multidimensional.jl        525 macro expansion                        \n",
      "   156 .\\multidimensional.jl        527 macro expansion                        \n",
      "    12 .\\multidimensional.jl        469 to_indices                             \n",
      "     5 .\\multidimensional.jl        476 uncolon                                \n",
      "     7 .\\multidimensional.jl        479 uncolon                                \n",
      "  5710 .\\profile.jl                  23 macro expansion                        \n",
      "    12 .\\range.jl                   764 convert                                \n",
      "  5711 .\\task.jl                    335 (::IJulia.##14#17)()                   \n",
      "    12 .\\tuple.jl                   284 ==(::Tuple{Int64}, ::Tuple{Int64})     \n",
      "    23 .\\tuple.jl                   285 ==(::Tuple{Int64}, ::Tuple{Int64})     \n",
      "     3 .\\tuple.jl                   289 ==(::Tuple{Int64}, ::Tuple{Int64})     \n",
      "  5711 ...IJulia\\src\\eventloop.jl     8 eventloop(::ZMQ.Socket)                \n",
      "  5711 ...\\src\\execute_request.jl   158 execute_request(::ZMQ.Socket, ::IJu... \n",
      "  5711 ....6\\Compat\\src\\Compat.jl    71 include_string(::Module, ::String, ... \n",
      "  5711 ....6\\Compat\\src\\Compat.jl   385 (::Compat.#inner#17{Array{Any,1},IJ... \n"
     ]
    }
   ],
   "source": [
    "Profile.clear()\n",
    "@profile nnmf(X,10, maxiter = 2, tol = 10.0^(-4))\n",
    "Profile.print(format=:flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readin matrix X\n",
    "path_X = \"http://Hua-Zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/nnmf-2429-by-361-face.txt\"\n",
    "X = readdlm(download(path_X), ' ')\n",
    "\n",
    "@time nnmf(X,10, maxiter = 1000, tol = 10.0^(-4))\n",
    "@time nnmf(X,10, maxiter = 1000, tol = 10.0^(-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "* Another trial question related is the rule of 80 character margin. I want to control the width limit for the file path. After I break down the file path into two lines, Julia will add `\\n` to the String, which resulted in the failure of reading the file. I guess I can write two strings and then combine them to solve the problem. But is there a better way than that? Below show the file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add package for visulizating image\n",
    "#Pkg.add(\"ImageView\")\n",
    "#Pkg.add(\"Images\")\n",
    "#Pkg.add(\"TestImages\")\n",
    "#Pkg.build(\"Cairo\")\n",
    "#Pkg.pin(\"Cairo\", v\"0.4.0\")\n",
    "#Pkg.update()\n",
    "using ImageView, Images\n",
    "\n",
    "# readin matrix file\n",
    "path_X = \"http://Hua-Zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/nnmf-2429-by-361-face.txt\"\n",
    "\n",
    "X = readdlm(download(path_X), ' ')\n",
    "\n",
    "# show first three face images\n",
    "for i in 1:3\n",
    "    # extract one row pixels to form one face image\n",
    "    img = reshape(X[1, :], 19, 19)\n",
    "    imshow(img)\n",
    "end\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Appreiciate your time on reading the long file. Hope you enjoy your day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
